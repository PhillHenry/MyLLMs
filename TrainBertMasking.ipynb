{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-07T10:42:45.084493Z",
     "start_time": "2025-05-07T10:42:43.689197Z"
    }
   },
   "source": [
    "import comet_ml\n",
    "from config import SAVED_MODEL\n",
    "\n",
    "comet_ml.init(api_key=\"wfYwSiDlqTHVyTWHjAuT6qI0P\")\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline, BertForMaskedLM, BertTokenizer\n",
    "from transformers import BertModel\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datetime import datetime\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Valid Comet API Key saved in /home/henryp/.comet.config (set COMET_CONFIG to change where it is saved).\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model",
   "id": "d2abb8e6dfeb78b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T10:42:47.795028Z",
     "start_time": "2025-05-07T10:42:47.041126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)"
   ],
   "id": "202484019870537",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data\n",
   "id": "87227b8e27a278a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T10:43:00.391537Z",
     "start_time": "2025-05-07T10:42:54.554308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"imdb\")  # or your own dataset\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")  # required by HF\n",
    "tokenized_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ],
   "id": "d755910c59c74794",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:20:29.500092Z",
     "start_time": "2025-05-07T10:43:46.734521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(tokenized_dataset['train'], batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(tokenized_dataset['test'], batch_size=8)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"comet_ml\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['test'],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "timestamp = datetime.now().strftime('%y%m%d%H%M')\n",
    "model_path = f\"{SAVED_MODEL}/{timestamp}/{model_name}\"\n",
    "print(f\"Will train model and save it to {model_path}\")\n",
    "trainer.train()\n",
    "\n"
   ],
   "id": "938a681065d033b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henryp/venv/llms/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, torch, keras, tensorflow.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will train model and save it to ./saved_model/2505071143/bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/phillhenry/general/f3f125fa11e34b3fbb41948b4a398fd7\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3125/3125 36:35, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.018000</td>\n",
       "      <td>1.896111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3125, training_loss=2.09102556640625, metrics={'train_runtime': 2200.8368, 'train_samples_per_second': 11.359, 'train_steps_per_second': 1.42, 'total_flos': 6580120320000000.0, 'train_loss': 2.09102556640625, 'epoch': 1.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:22:25.973718Z",
     "start_time": "2025-05-07T11:22:23.863158Z"
    }
   },
   "cell_type": "code",
   "source": "comet_ml.experiment.end()",
   "id": "7580aa0057d26797",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : olympic_arch_4399\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/phillhenry/general/f3f125fa11e34b3fbb41948b4a398fd7\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     eval/loss                      : 1.8961111307144165\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     eval/runtime                   : 529.9033\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     eval/samples_per_second        : 47.178\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     eval/steps_per_second          : 5.897\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/epoch [8]                : (0.16, 1.0)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/grad_norm [6]            : (5.760892391204834, 7.740053653717041)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/learning_rate [6]        : (2.0000000000000003e-06, 4.2e-05)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/loss [6]                 : (2.018, 2.2188)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/total_flos               : 6580120320000000.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_loss               : 2.09102556640625\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_runtime            : 2200.8368\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_samples_per_second : 11.359\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     train/train_steps_per_second   : 1.42\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Others:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     hasNestedParams : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|dispatch_batches             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|even_batches                 : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|gradient_accumulation_kwargs : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|non_blocking                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|split_batches                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|accelerator_config|use_seedable_sampler         : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|adafactor                                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|adam_beta1                                      : 0.9\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|adam_beta2                                      : 0.999\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|adam_epsilon                                    : 1e-08\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|auto_find_batch_size                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|average_tokens_across_devices                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|batch_eval_metrics                              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|bf16                                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|bf16_full_eval                                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|data_seed                                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dataloader_drop_last                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dataloader_num_workers                          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dataloader_persistent_workers                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dataloader_pin_memory                           : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dataloader_prefetch_factor                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ddp_backend                                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ddp_broadcast_buffers                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ddp_bucket_cap_mb                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ddp_find_unused_parameters                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ddp_timeout                                     : 1800\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|debug                                           : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|deepspeed                                       : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|disable_tqdm                                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|dispatch_batches                                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|do_eval                                         : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|do_predict                                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|do_train                                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_accumulation_steps                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_delay                                      : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_do_concat_batches                          : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_on_start                                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_steps                                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_strategy                                   : epoch\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|eval_use_gather_object                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|evaluation_strategy                             : epoch\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fp16                                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fp16_backend                                    : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fp16_full_eval                                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fp16_opt_level                                  : O1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp                                            : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_config|min_num_params                      : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_config|xla                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_config|xla_fsdp_grad_ckpt                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_config|xla_fsdp_v2                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_min_num_params                             : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|fsdp_transformer_layer_cls_to_wrap              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|full_determinism                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|gradient_accumulation_steps                     : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|gradient_checkpointing                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|gradient_checkpointing_kwargs                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|greater_is_better                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|group_by_length                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|half_precision_backend                          : auto\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|hub_always_push                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|hub_model_id                                    : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|hub_private_repo                                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|hub_strategy                                    : every_save\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|hub_token                                       : <HUB_TOKEN>\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ignore_data_skip                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|include_for_metrics                             : []\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|include_inputs_for_metrics                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|include_num_input_tokens_seen                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|include_tokens_per_second                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|jit_mode_eval                                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|label_names                                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|label_smoothing_factor                          : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|learning_rate                                   : 5e-05\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|length_column_name                              : length\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|load_best_model_at_end                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|local_rank                                      : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|log_level                                       : passive\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|log_level_replica                               : warning\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|log_on_each_node                                : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|logging_dir                                     : ./logs\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|logging_first_step                              : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|logging_nan_inf_filter                          : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|logging_steps                                   : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|logging_strategy                                : steps\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|lr_scheduler_kwargs                             : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|lr_scheduler_type                               : linear\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|max_grad_norm                                   : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|max_steps                                       : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|metric_for_best_model                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|mp_parameters                                   : \n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|neftune_noise_alpha                             : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|no_cuda                                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|num_train_epochs                                : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|optim                                           : adamw_torch\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|optim_args                                      : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|optim_target_modules                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|output_dir                                      : ./results\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|overwrite_output_dir                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|past_index                                      : -1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|per_device_eval_batch_size                      : 8\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|per_device_train_batch_size                     : 8\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|per_gpu_eval_batch_size                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|per_gpu_train_batch_size                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|prediction_loss_only                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|push_to_hub                                     : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|push_to_hub_model_id                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|push_to_hub_organization                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|push_to_hub_token                               : <PUSH_TO_HUB_TOKEN>\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|ray_scope                                       : last\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|remove_unused_columns                           : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|report_to                                       : ['comet_ml']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|restore_callback_states_from_checkpoint         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|resume_from_checkpoint                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|run_name                                        : ./results\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_on_each_node                               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_only_model                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_safetensors                                : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_steps                                      : 500\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_strategy                                   : steps\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|save_total_limit                                : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|seed                                            : 42\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|skip_memory_metrics                             : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|split_batches                                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|tf32                                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|torch_compile                                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|torch_compile_backend                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|torch_compile_mode                              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|torch_empty_cache_steps                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|torchdynamo                                     : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|tpu_metrics_debug                               : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|tpu_num_cores                                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|use_cpu                                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|use_ipex                                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|use_legacy_prediction_loop                      : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|use_liger_kernel                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|use_mps_device                                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|warmup_ratio                                    : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|warmup_steps                                    : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     args|weight_decay                                    : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|_attn_implementation_autoset                  : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|_name_or_path                                 : bert-base-uncased\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|add_cross_attention                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|architectures                                 : ['BertForMaskedLM']\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|attention_probs_dropout_prob                  : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|bad_words_ids                                 : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|begin_suppress_tokens                         : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|bos_token_id                                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|chunk_size_feed_forward                       : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|classifier_dropout                            : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|cross_attention_hidden_size                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|decoder_start_token_id                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|diversity_penalty                             : 0.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|do_sample                                     : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|early_stopping                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|encoder_no_repeat_ngram_size                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|eos_token_id                                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|exponential_decay_length_penalty              : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|finetuning_task                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|forced_bos_token_id                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|forced_eos_token_id                           : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|gradient_checkpointing                        : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|hidden_act                                    : gelu\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|hidden_dropout_prob                           : 0.1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|hidden_size                                   : 768\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|id2label|0                                    : LABEL_0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|id2label|1                                    : LABEL_1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|initializer_range                             : 0.02\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|intermediate_size                             : 3072\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|is_decoder                                    : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|is_encoder_decoder                            : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|label2id|LABEL_0                              : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|label2id|LABEL_1                              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|layer_norm_eps                                : 1e-12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|length_penalty                                : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|max_length                                    : 20\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|max_position_embeddings                       : 512\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|min_length                                    : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|model_type                                    : bert\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|no_repeat_ngram_size                          : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|num_attention_heads                           : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|num_beam_groups                               : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|num_beams                                     : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|num_hidden_layers                             : 12\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|num_return_sequences                          : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|output_attentions                             : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|output_hidden_states                          : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|output_scores                                 : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|pad_token_id                                  : 0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|position_embedding_type                       : absolute\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|prefix                                        : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|problem_type                                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|pruned_heads                                  : {}\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|remove_invalid_values                         : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|repetition_penalty                            : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|return_dict                                   : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|return_dict_in_generate                       : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|sep_token_id                                  : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|suppress_tokens                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|task_specific_params                          : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|temperature                                   : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|tf_legacy_loss                                : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|tie_encoder_decoder                           : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|tie_word_embeddings                           : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|tokenizer_class                               : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|top_k                                         : 50\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|top_p                                         : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|torch_dtype                                   : None\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|torchscript                                   : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|transformers_version                          : 4.48.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|type_vocab_size                               : 2\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|typical_p                                     : 1.0\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|use_bfloat16                                  : False\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|use_cache                                     : True\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     config|vocab_size                                    : 30522\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata             : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git-patch (uncompressed) : 1 (11.62 KB)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages       : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model graph              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook                 : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     os packages              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code              : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: sklearn, torch, keras, tensorflow.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:22:51.293018Z",
     "start_time": "2025-05-07T11:22:50.793643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#model_path = f\"{MyLlamaModel.base_output_dir}/{model_name}\"\n",
    "\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(f\"{model_path}_tokenizer\")\n",
    "tokenizer.save_vocabulary(f\"{model_path}_vocab\")\n",
    "#model.save_pretrained_merged(model_path, tokenizer=tokenizer) # merged_4bit_forced\n",
    "print(\"finished\")"
   ],
   "id": "2579b55e9af9cbbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:26:41.128915Z",
     "start_time": "2025-05-07T11:26:41.095897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)\n",
    "print(unmasker(\"Hello I'm a [MASK] model.\"))"
   ],
   "id": "cc7210875cfcbb03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.19769975543022156, 'token': 2535, 'token_str': 'role', 'sequence': \"hello i'm a role model.\"}, {'score': 0.0841338112950325, 'token': 4827, 'token_str': 'fashion', 'sequence': \"hello i'm a fashion model.\"}, {'score': 0.04360273852944374, 'token': 2307, 'token_str': 'great', 'sequence': \"hello i'm a great model.\"}, {'score': 0.04252929985523224, 'token': 3287, 'token_str': 'male', 'sequence': \"hello i'm a male model.\"}, {'score': 0.03406408801674843, 'token': 3565, 'token_str': 'super', 'sequence': \"hello i'm a super model.\"}]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-07T11:27:08.864378Z",
     "start_time": "2025-05-07T11:27:08.845537Z"
    }
   },
   "cell_type": "code",
   "source": "print(unmasker(\"The Empire Strikes [MASK]\"))",
   "id": "c2785c4c21f8afe2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9441056251525879, 'token': 999, 'token_str': '!', 'sequence': 'the empire strikes!'}, {'score': 0.05120796710252762, 'token': 1012, 'token_str': '.', 'sequence': 'the empire strikes.'}, {'score': 0.003980387933552265, 'token': 1025, 'token_str': ';', 'sequence': 'the empire strikes ;'}, {'score': 0.000549117277842015, 'token': 1029, 'token_str': '?', 'sequence': 'the empire strikes?'}, {'score': 4.1509574657538906e-05, 'token': 1064, 'token_str': '|', 'sequence': 'the empire strikes |'}]\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
